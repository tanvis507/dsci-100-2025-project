{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b1a2f2e",
   "metadata": {},
   "source": [
    "# Predicting Newsletter Subscription from Player Behavior\n",
    "\n",
    "# Introduction\n",
    "\n",
    "In this project, we explore whether it is possible to predict whether a player will subscribe to a video game newsletter based on their in-game behavior and personal characteristics. The dataset comes from a UBC research group studying player actions on a Minecraft server.\n",
    "\n",
    "We focus on a classification problem: can we predict the `subscribe` status (True or False) using player attributes such as their experience level, total hours played, age, and gender?\n",
    "\n",
    "To address this question, we follow the complete data science workflow: loading and cleaning the dataset, performing exploratory data analysis (EDA), building a predictive model using the `tidymodels` framework, and evaluating model performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2ee305",
   "metadata": {},
   "source": [
    "## Methods and Results \n",
    "### Data Description\n",
    "\n",
    "The dataset used in this project is `players.csv`, which contains information about individual players on a Minecraft server. Each row corresponds to a unique player and includes variables such as:\n",
    "\n",
    "- `Age`: The player's age in years.\n",
    "- `gender`: The self-reported gender of the player.\n",
    "- `experience`: The player's reported experience level in Minecraft (e.g., beginner, intermediate, advanced).\n",
    "- `played_hours`: The total number of hours the player has spent in-game.\n",
    "- `subscribe`: A binary indicator (`TRUE` or `FALSE`) showing whether the player subscribed to the newsletter.\n",
    "\n",
    "To prepare the dataset for analysis, we performed the following cleaning steps:\n",
    "- Removed rows with missing `Age` values.\n",
    "- Converted `subscribe`, `experience`, and `gender` into categorical (factor) variables for modeling.\n",
    "\n",
    "The cleaned dataset is stored in a new object called `players_clean`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674164f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "\n",
    "# Load the players data\n",
    "players <- read_csv(\"players.csv\")\n",
    "\n",
    "# Clean the dataset by removing missing age values and convert needed columns to factors\n",
    "players_clean <- players |>\n",
    "  filter(!is.na(Age))|>\n",
    "  mutate(\n",
    "    subscribe = as.factor(subscribe),\n",
    "    experience = as.factor(experience),\n",
    "    gender = as.factor(gender)\n",
    "  )\n",
    "players_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15734197",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "After cleaning the data, we proceeded to split the dataset into training and testing sets in preparation for model building.\n",
    "\n",
    "To ensure the class balance of the `subscribe` variable is maintained across both sets, we used **stratified sampling**, selecting 75% of the data for training and 25% for testing. We set a random seed to make the results reproducible.\n",
    "\n",
    "- **Training set**: 145 observations  \n",
    "- **Testing set**: 49 observations\n",
    "\n",
    "Below is a summary of the structure of each dataset:\n",
    "- `glimpse(train_players)` shows the variable types and a preview of the training data.\n",
    "- `glimpse(test_players)` shows the same for the test data.\n",
    "\n",
    "This allows us to confirm that the data is correctly formatted and ready for exploratory data analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234) # to reproduce result\n",
    "\n",
    "data_split <- initial_split(players_clean, prop = 0.75, strata = subscribe)\n",
    "train_players <- training(data_split)\n",
    "test_players <- testing(data_split)\n",
    "\n",
    "glimpse(train_players)\n",
    "glimpse(test_players)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dd53b1",
   "metadata": {},
   "source": [
    "## Class Proportions & Data Preprocessing\n",
    "Before modeling, we examined the proportion of players who subscribed to the newsletter in the training set. This helps us understand class balance, which is important in classification tasks. We found that approximately **73%** of players subscribed (`TRUE`), while about **27%** did not (`FALSE`). This suggests a moderate class imbalance, which our model will need to handle.\n",
    "\n",
    "To prepare for modeling with K-nearest neighbors (KNN), we created a recipe that defines the preprocessing steps. KNN is sensitive to the scale of numeric features, so we **standardized** (`step_scale`) and **centered** (`step_center`) the numeric predictors—`Age` and `played_hours`.\n",
    "\n",
    "We then built a KNN model using 3 neighbors and specified a rectangular weighting function. The model was combined with the recipe in a workflow and trained on the training data using the `fit()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_proportions <- train_players |>\n",
    "                      group_by(subscribe) |>\n",
    "                      summarize(n = n()) |>\n",
    "                      mutate(percent = 100*n/nrow(train_players))\n",
    "\n",
    "players_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e244a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "players_recipe <- recipe(subscribe ~ experience + gender + Age + played_hours, data = train_players) |>\n",
    " step_scale(all_numeric_predictors()) |>\n",
    "  step_center(all_numeric_predictors())\n",
    "\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 3) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "knn_fit <- workflow() |>\n",
    "  add_recipe(players_recipe) |>\n",
    "  add_model(knn_spec) |>\n",
    "  fit(data = train_players)\n",
    "\n",
    "knn_fit\n",
    "\n",
    "players_test_predictions <- predict(knn_fit, test_players, type = \"class\") |>\n",
    "  bind_cols(test_players)\n",
    "\n",
    "players_test_predictions\n",
    "\n",
    "knn_metrics <- players_test_predictions|>\n",
    "  metrics(truth = subscribe, estimate = .pred_class)\n",
    "\n",
    "# Confusion matrix\n",
    "knn_conf_mat <- players_test_predictions|> \n",
    "  conf_mat(truth = subscribe, estimate = .pred_class)\n",
    "\n",
    "# Show results\n",
    "knn_metrics\n",
    "knn_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a992f8e",
   "metadata": {},
   "source": [
    "We evaluated the model using the test set. The metric accuracy tells us how often the model correctly predicts a player's subscription status. We also looked at the confusion matrix to understand the types of mistakes the model is making.\n",
    "\n",
    "- **True Positives**: players correctly predicted to subscribe\n",
    "- **True Negatives**: players correctly predicted not to subscribe\n",
    "- **False Positives**: players incorrectly predicted to subscribe\n",
    "- **False Negatives**: players incorrectly predicted not to subscribe\n",
    "\n",
    "These results will help us assess the model's effectiveness in identifying potential newsletter subscribers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda1f0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_test_predictions |>\n",
    "  metrics(truth = subscribe, estimate = .pred_class) |>\n",
    "  filter(.metric == \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f0c7e",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "After evaluating the final model on the test set using accuracy as the main metric. With `k = 3`, the KNN model reached an accuracy of about **71.4%**.\n",
    "\n",
    "This means it was able to correctly predict whether or not a player would subscribe around 71% of the time. While the model performs reasonably well, its accuracy could be improved with further tuning or more advanced methods.\n",
    "\n",
    "Notably, we chose KNN because it is a simple, interpretable model that classifies observations based on the majority vote of their nearest neighbors. It performs well when the relationship between predictors and the response is nonlinear.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f61bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "# Create a split from the existing training data\n",
    "subsplit <- initial_split(train_players, prop = 0.75, strata = subscribe)\n",
    "subtrain <- training(subsplit)\n",
    "validation <- testing(subsplit)\n",
    "\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 3) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "knn_recipe <- recipe(subscribe ~ played_hours + Age, data = subtrain) |>\n",
    "  step_scale(all_numeric_predictors()) |>\n",
    "  step_center(all_numeric_predictors())\n",
    "\n",
    "knn_workflow <- workflow() |>\n",
    "  add_recipe(knn_recipe) |>\n",
    "  add_model(knn_spec)\n",
    "\n",
    "knn_fit <- fit(knn_workflow, data = subtrain)\n",
    "\n",
    "validation_predictions <- predict(knn_fit, validation) |>\n",
    "  bind_cols(validation)\n",
    "\n",
    "validation_accuracy <- validation_predictions |>\n",
    "  metrics(truth = subscribe, estimate = .pred_class) |>\n",
    "  filter(.metric == \"accuracy\") |>\n",
    "  pull(.estimate)\n",
    "\n",
    "validation_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d662115f",
   "metadata": {},
   "source": [
    "### Validation Accuracy\n",
    "\n",
    "The KNN model with `k = 3` achieved a validation accuracy of approximately **62.2%**, meaning it correctly predicted subscription status about 62% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4bac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscription rate by experience\n",
    "ggplot(players_clean, aes(x = experience, fill = subscribe)) +\n",
    "  geom_bar(position = \"fill\") +\n",
    "  labs(title = \"Proportion of Subscribers by Experience Level\", y = \"Proportion\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# Hours played by subscription status\n",
    "ggplot(players_clean, aes(x = subscribe, y = played_hours, fill = subscribe)) +\n",
    "  stat_summary(fun = mean, geom = \"bar\") +\n",
    "  labs(title = \"Average Hours Played by Subscription Status\",\n",
    "       x = \"Subscribed\", y = \"Average Hours Played\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# Age by subscription status\n",
    "ggplot(players_clean, aes(x = subscribe, y = Age, fill = subscribe)) +\n",
    "  stat_summary(fun = mean, geom = \"bar\") +\n",
    "  labs(title = \"Average Age by Subscription Status\",\n",
    "       x = \"Subscribed\", y = \"Average Age\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb4670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75114e49",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "\n",
    "### Figure 1. Proportion of Subscribers by Experience Level\n",
    "We used a proportion bar chart to compare subscription rates across different experience levels.\n",
    "Observation: Subscription rates appear slightly higher for players with more experience, such as \"Regular\" and \"Pro\" players. Beginners and amateurs showed slightly lower proportions of subscription.\n",
    "\n",
    "### Figure 2. Average Hours Played by Subscription Status\n",
    "We compared the average number of hours played by subscribers vs. non-subscribers using a bar plot.\n",
    "Observation: Players who subscribed to the newsletter played significantly more hours on average than those who didn’t. This suggests that more engaged players may be more likely to subscribe.\n",
    "\n",
    "### Figure 3. Average Age by Subscription Status\n",
    "This plot shows the average age of players based on their subscription status.\n",
    "Observation: Players who subscribed tended to be younger on average compared to those who didn’t. This could indicate that younger players are more likely to engage with game-related content outside of gameplay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c37865",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "vfolds <- vfold_cv(train_players, v = 5, strata = subscribe)\n",
    "\n",
    "knn_spec <- nearest_neighbor(\n",
    "  weight_func = \"rectangular\",\n",
    "  neighbors = tune()\n",
    ") |> \n",
    "  set_engine(\"kknn\") |> \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Create grid of K values to test\n",
    "gridvals <- tibble(neighbors = seq(1, 15, by = 2))\n",
    "\n",
    "\n",
    "knn_tune_results <- workflow() |>\n",
    "  add_recipe(knn_recipe) |>\n",
    "  add_model(knn_spec) |>\n",
    "  tune_grid(resamples = vfolds, grid = gridvals)\n",
    "\n",
    "\n",
    "knn_tune_results |>\n",
    "  collect_metrics() |>\n",
    "  filter(.metric == \"accuracy\") |>\n",
    "  ggplot(aes(x = neighbors, y = mean)) +\n",
    "  geom_line() +\n",
    "  geom_point() +\n",
    "  labs(title = \"Accuracy vs K (Cross-Validation)\",\n",
    "       x = \"Number of Neighbors (K)\",\n",
    "       y = \"Mean Accuracy\") +\n",
    "  theme_minimal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe514f87",
   "metadata": {},
   "source": [
    "## Figure 4. Accuracy vs. K (Cross-Validation)\n",
    "This line plot shows mean cross-validation accuracy across different values of K. The best performance was observed at K = 15, which we used in our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f2f448",
   "metadata": {},
   "source": [
    "### Model Tuning\n",
    "\n",
    "To improve the model, I performed 5-fold cross-validation using different values of \\( k \\) (the number of neighbors). The accuracy was calculated for each value in the range from 1 to 15 (by 2s). The results are visualized in the plot below.\n",
    "\n",
    "From the graph, we can see that accuracy improves as \\( k \\) increases, peaking at \\( k = 15 \\). This suggests that using more neighbors might lead to better model performance, potentially due to smoothing out noise in the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ba00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k <- knn_tune_results |>\n",
    "  collect_metrics() |>\n",
    "  filter(.metric == \"accuracy\") |>\n",
    "  arrange(desc(mean)) |>\n",
    "  slice(1) |>\n",
    "  pull(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13631ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = best_k) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "final_workflow <- workflow() |>\n",
    "  add_recipe(knn_recipe) |>\n",
    "  add_model(final_spec)\n",
    "\n",
    "final_fit <- fit(final_workflow, data = train_players)\n",
    "\n",
    "final_predictions <- predict(final_fit, test_players) |>\n",
    "  bind_cols(test_players)\n",
    "\n",
    "final_metrics <- final_predictions |>\n",
    "  metrics(truth = subscribe, estimate = .pred_class)\n",
    "\n",
    "final_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80fe642",
   "metadata": {},
   "source": [
    "### Model Tuning and Best K Selection\n",
    "\n",
    "To improve the performance of our KNN model, we performed 5-fold cross-validation using a range of `k` values from 1 to 15. The accuracy for each value of `k` was recorded and plotted. The cross-validation results show that model accuracy varies with the number of neighbors used.\n",
    "\n",
    "We selected the value of `k` that achieved the highest mean accuracy across the folds. This value will be used to train our final model on the full training set, which will then be evaluated on the test data to assess generalization performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a9cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model training using the best k value from cross-validation\n",
    "best_k <- 15 \n",
    "\n",
    "final_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = best_k) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "final_recipe <- recipe(subscribe ~ played_hours + Age, data = train_players) |>\n",
    "  step_scale(all_numeric_predictors()) |>\n",
    "  step_center(all_numeric_predictors())\n",
    "\n",
    "final_workflow <- workflow() |>\n",
    "  add_recipe(final_recipe) |>\n",
    "  add_model(final_spec)\n",
    "\n",
    "# Fit the final model\n",
    "final_fit <- fit(final_workflow, data = train_players)\n",
    "\n",
    "# Predict on the test set\n",
    "final_predictions <- predict(final_fit, test_players) |>\n",
    "  bind_cols(test_players)\n",
    "\n",
    "# Evaluate final accuracy on the test set\n",
    "final_accuracy <- final_predictions |>\n",
    "  metrics(truth = subscribe, estimate = .pred_class) |>\n",
    "  filter(.metric == \"accuracy\")\n",
    "\n",
    "final_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb9154e",
   "metadata": {},
   "source": [
    "### Final Model Evaluation\n",
    "\n",
    "Using the best `k` value found through cross-validation, we trained our final KNN model on the full training set and evaluated its performance on the test set. The model achieved an accuracy of approximately **69.4%**.\n",
    "\n",
    "This result suggests that the model correctly predicted whether a player would subscribe about 69% of the time. While the performance is moderate, it offers a solid baseline that could be improved further with more complex models or additional features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688a4c70",
   "metadata": {},
   "source": [
    "### Discussion & Conclusion\n",
    "\n",
    "In this project, we explored whether player characteristics such as age, total hours played, and experience level could be used to predict subscription to a game-related newsletter. After cleaning the data and performing a data analysis, we trained a K-nearest neighbors (KNN) classifier and tuned it using cross-validation. The final model achieved an accuracy of approximately 69.4% on the test set.\n",
    "\n",
    "These results suggest that player behaviour holds some predictive value. Players with more experience and greater total playtime appeared slightly more likely to subscribe, while age showed a less consistent pattern. This outcome mostly aligned with our expectations. We predicted that players who were more active or had more gaming experience would be more engaged and therefore more likely to subscribe.\n",
    "\n",
    "The findings could have practical implications. For example, game developers or researchers may use behavioral features to identify players who are more likely to respond to outreach efforts. This can support better decision-making in areas like marketing or resource planning.\n",
    "\n",
    "There are several limitations to consider. The model included only a few variables, and incorporating additional predictors from the session-level data might improve performance. Also, KNN is a relatively simple method and may not capture complex or nonlinear patterns. Additionally, some players might subscribe or choose not to for reasons that are not reflected in the dataset.\n",
    "\n",
    "In the future, it would be helpful to explore more advanced models such as logistic regression or decision trees. Including more detailed behavioral data, such as timing or frequency of gameplay, could lead to more accurate predictions. Further questions could examine how player behavior changes over time or whether certain types of gameplay are stronger indicators of subscription.\n",
    "\n",
    "Overall, this project demonstrates how basic data science tools can uncover meaningful patterns and help build predictive models, even with limited features.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a0df12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
